# Data Pipelines Learning Repository

Welcome to the **Data Management for Business Intelligence (DM4BI)** learning repository! This repository is designed to help you learn about data pipelines, ETL processes, and data engineering fundamentals.

## ğŸ“š What You'll Learn

- **Data Pipeline Fundamentals**: Understanding the basics of data pipelines and their components
- **ETL/ELT Processes**: Extract, Transform, Load patterns and best practices
- **Data Transformation**: Techniques for cleaning, validating, and transforming data
- **Workflow Orchestration**: Using tools like Apache Airflow for pipeline management
- **Data Quality**: Ensuring data integrity and reliability
- **Best Practices**: Industry standards and common patterns in data engineering

## ğŸ—‚ï¸ Repository Structure

```
dm4bi-2026/
â”œâ”€â”€ docs/               # Documentation and learning materials
â”œâ”€â”€ examples/           # Practical examples of data pipelines
â”œâ”€â”€ exercises/          # Hands-on exercises to practice
â”œâ”€â”€ data/              # Sample datasets for learning
â””â”€â”€ requirements.txt   # Python dependencies
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- Basic knowledge of Python programming
- Understanding of databases and SQL (helpful but not required)

### Installation

1. Clone this repository:
```bash
git clone https://github.com/roger-lloret/dm4bi-2026.git
cd dm4bi-2026
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## ğŸ“– Learning Path

1. **Start with Documentation** (`docs/`): Read through the conceptual materials
2. **Explore Examples** (`examples/`): Run and study the example pipelines
3. **Practice with Exercises** (`exercises/`): Complete hands-on exercises to reinforce learning

## ğŸ”§ Technologies Covered

- **Python**: Primary programming language
- **Pandas**: Data manipulation and analysis
- **Apache Airflow**: Workflow orchestration
- **SQL**: Database interactions
- **CSV/JSON/Parquet**: Various data formats

## ğŸ“ Topics Covered

1. Introduction to Data Pipelines
2. ETL vs ELT
3. Data Extraction from various sources
4. Data Transformation techniques
5. Data Loading strategies
6. Pipeline orchestration with Airflow
7. Error handling and monitoring
8. Data quality and validation

## ğŸ¤ Contributing

This is a learning repository. Feel free to add your own examples, improve documentation, or suggest new topics!

## ğŸ“„ License

This repository is for educational purposes.

## ğŸ”— Additional Resources

- [Apache Airflow Documentation](https://airflow.apache.org/)
- [Pandas Documentation](https://pandas.pydata.org/)
- [Data Engineering Best Practices](https://www.dataengineeringweekly.com/)

---

Happy Learning! ğŸ“
