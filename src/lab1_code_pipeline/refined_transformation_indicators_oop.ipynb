{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b223bc08",
   "metadata": {},
   "source": [
    "# Part 4 — Object-Oriented ETL Framework\n",
    "\n",
    "This notebook demonstrates a **reusable OOP design** for ETL pipelines using pandas.\n",
    "\n",
    "**Design principles:**\n",
    "\n",
    "| Principle | Description |\n",
    "|-----------|-------------|\n",
    "| **Abstract Base Classes** | Define the contract every pipeline must follow |\n",
    "| **Dependency Injection** | Pass a `DatabaseManager` in; don't create it inside |\n",
    "| **Plug-in KPIs** | Register KPI classes in a list; add new ones without touching the orchestrator |\n",
    "| **Template Method** | `BasePipeline.run()` calls extract → transform → build_kpis → load |\n",
    "\n",
    "**Class hierarchy:**\n",
    "```\n",
    "DatabaseManager          — reusable DB I/O\n",
    "BaseTransformer (ABC)    — override transform()\n",
    "BaseKPI (ABC)            — override build()\n",
    "BasePipeline (ABC)       — override extract / get_transformer / get_kpis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed668ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tracemalloc\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import Engine\n",
    "\n",
    "# Start performance tracking\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path.cwd()\n",
    "CREDS_PATH = Path(\"C:/Users/roger.lloret/Documents/creds/creds_dmbi.yml\")\n",
    "SQL_DIR = BASE_DIR / \"sql\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ad196e",
   "metadata": {},
   "source": [
    "## Reusable: DatabaseManager\n",
    "\n",
    "A generic database helper. Inject credentials at construction time; reuse the same instance across any number of pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseManager:\n",
    "    \"\"\"\n",
    "    Generic database helper. Inject credentials at construction time;\n",
    "    reuse the same instance across any number of pipelines.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, creds: dict):\n",
    "        conn_str = (\n",
    "            f\"mysql://{creds['username']}:{creds['password']}\"\n",
    "            f\"@{creds['host']}:3306/{creds['database']}\"\n",
    "        )\n",
    "        self.engine: Engine = create_engine(conn_str)\n",
    "\n",
    "    def read(self, query: str) -> pd.DataFrame:\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "    def write(self, df: pd.DataFrame, table_name: str, if_exists: str = \"append\"):\n",
    "        with self.engine.begin() as conn:\n",
    "            df.to_sql(table_name, con=conn, if_exists=if_exists, index=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_sql(filepath: Path) -> str:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "\n",
    "    @staticmethod\n",
    "    def load_credentials(path: Path) -> dict:\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Credentials file not found at {path}\")\n",
    "        with open(path, \"r\") as f:\n",
    "            return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f79271",
   "metadata": {},
   "source": [
    "## Reusable: Abstract Base Classes\n",
    "\n",
    "These ABCs define the **contract** every pipeline component must follow. Any new pipeline just subclasses and overrides the relevant methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTransformer(ABC):\n",
    "    \"\"\"Override transform() with your domain-specific logic.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, **dataframes) -> pd.DataFrame:\n",
    "        \"\"\"Receive named raw DataFrames, return a single transformed DataFrame.\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class BaseKPI(ABC):\n",
    "    \"\"\"\n",
    "    Each KPI is its own class. To add a new metric:\n",
    "      1. Subclass BaseKPI\n",
    "      2. Implement build()\n",
    "      3. Register it in the pipeline's get_kpis() list\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def build(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Return a DataFrame with columns [kpi_name, kpi_value].\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class BasePipeline(ABC):\n",
    "    \"\"\"\n",
    "    Template-method pattern: run() calls extract -> transform -> build_kpis -> load.\n",
    "    Subclasses only override the parts that change.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db: DatabaseManager, table_name: str):\n",
    "        self.db = db\n",
    "        self.table_name = table_name\n",
    "\n",
    "    @abstractmethod\n",
    "    def extract(self) -> dict[str, pd.DataFrame]:\n",
    "        \"\"\"Return a dict of named DataFrames.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_transformer(self) -> BaseTransformer:\n",
    "        \"\"\"Return the transformer instance for this pipeline.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_kpis(self) -> list[BaseKPI]:\n",
    "        \"\"\"Return the list of KPI builders to apply.\"\"\"\n",
    "        ...\n",
    "\n",
    "    # --- Shared logic (no need to override) ---\n",
    "\n",
    "    def build_kpis(self, merged: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Runs every registered KPI and concatenates results.\"\"\"\n",
    "        frames = [kpi.build(merged) for kpi in self.get_kpis()]\n",
    "        result = pd.concat(frames)\n",
    "        result[\"kpi_date\"] = date.today()\n",
    "        return result[[\"kpi_date\", \"kpi_name\", \"kpi_value\"]]\n",
    "\n",
    "    def load(self, df: pd.DataFrame):\n",
    "        print(f\"Loading {len(df)} rows to '{self.table_name}'...\")\n",
    "        self.db.write(df, self.table_name)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Template method — orchestrates the full pipeline.\"\"\"\n",
    "        raw = self.extract()\n",
    "        merged = self.get_transformer().transform(**raw)\n",
    "        output = self.build_kpis(merged)\n",
    "        self.load(output)\n",
    "        print(\"Pipeline completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5568b9",
   "metadata": {},
   "source": [
    "## Concrete: InvoiceTransformer\n",
    "\n",
    "Deduplicates, classifies, casts, and merges invoices + contracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvoiceTransformer(BaseTransformer):\n",
    "    \"\"\"Deduplicates, classifies, casts, and merges invoices + contracts.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def classify(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "        conditions = [\n",
    "            df[column] < 50,\n",
    "            (df[column] >= 50) & (df[column] <= 100),\n",
    "            df[column] > 100,\n",
    "        ]\n",
    "        choices = [\"Less than 50\", \"Between 50 and 100\", \"Greater than 100\"]\n",
    "        df[\"category\"] = np.select(conditions, choices, default=\"Invalid Input\")\n",
    "        return df\n",
    "\n",
    "    def transform(self, *, invoices: pd.DataFrame, contracts: pd.DataFrame) -> pd.DataFrame:\n",
    "        print(\"Transforming data...\")\n",
    "        contracts = contracts.drop_duplicates()\n",
    "        invoices = self.classify(invoices, \"total_import_euros\")\n",
    "        invoices[\"contract_id\"] = pd.to_numeric(invoices[\"contract_id\"], errors=\"coerce\")\n",
    "        contracts[\"contract_id\"] = pd.to_numeric(contracts[\"contract_id\"], errors=\"coerce\")\n",
    "        return invoices.merge(contracts, on=\"contract_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de647ed6",
   "metadata": {},
   "source": [
    "## Concrete: KPI Definitions\n",
    "\n",
    "Each KPI is its own class. To add a new metric, just subclass `BaseKPI` and register it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmountByCategoryKPI(BaseKPI):\n",
    "    \"\"\"KPI 1: Total amount by invoice category and client type.\"\"\"\n",
    "\n",
    "    def build(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        result = (\n",
    "            df\n",
    "            .groupby([\"category\", \"client_type_description\"])[\"total_import_euros\"]\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        )\n",
    "        result[\"kpi_name\"] = (\n",
    "            \"Total amount in euros of the customers with invoices \"\n",
    "            + result[\"category\"]\n",
    "            + \" euros and \"\n",
    "            + result[\"client_type_description\"]\n",
    "        )\n",
    "        return result.rename(columns={\"total_import_euros\": \"kpi_value\"})[[\"kpi_name\", \"kpi_value\"]]\n",
    "\n",
    "\n",
    "class CountByDocTypeKPI(BaseKPI):\n",
    "    \"\"\"KPI 2: Invoice count by document type.\"\"\"\n",
    "\n",
    "    def build(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        result = (\n",
    "            df\n",
    "            .groupby(\"document_type_description\")[\"total_import_euros\"]\n",
    "            .count()\n",
    "            .reset_index()\n",
    "        )\n",
    "        result[\"kpi_name\"] = \"Number of invoices of invoice type \" + result[\"document_type_description\"]\n",
    "        return result.rename(columns={\"total_import_euros\": \"kpi_value\"})[[\"kpi_name\", \"kpi_value\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c10540d",
   "metadata": {},
   "source": [
    "## Concrete: InvoiceKPIPipeline\n",
    "\n",
    "Wires the transformer and KPIs together. To create a different pipeline (e.g., consumption KPIs), subclass `BasePipeline` and override `extract()`, `get_transformer()`, and `get_kpis()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83182ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvoiceKPIPipeline(BasePipeline):\n",
    "    \"\"\"\n",
    "    Concrete pipeline for invoice KPIs.\n",
    "    To create a different pipeline (e.g. consumption KPIs):\n",
    "      1. Subclass BasePipeline\n",
    "      2. Override extract(), get_transformer(), get_kpis()\n",
    "      3. Call .run()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db: DatabaseManager, sql_dir: Path, table_name: str = \"gen_kpi_ft\"):\n",
    "        super().__init__(db, table_name)\n",
    "        self.sql_dir = sql_dir\n",
    "\n",
    "    def extract(self) -> dict[str, pd.DataFrame]:\n",
    "        print(\"Extracting data from database...\")\n",
    "        invoices_sql = DatabaseManager.load_sql(self.sql_dir / \"invoices_main.sql\")\n",
    "        contracts_sql = DatabaseManager.load_sql(self.sql_dir / \"contracts_main.sql\")\n",
    "        return {\n",
    "            \"invoices\": self.db.read(invoices_sql),\n",
    "            \"contracts\": self.db.read(contracts_sql),\n",
    "        }\n",
    "\n",
    "    def get_transformer(self) -> BaseTransformer:\n",
    "        return InvoiceTransformer()\n",
    "\n",
    "    def get_kpis(self) -> list[BaseKPI]:\n",
    "        return [\n",
    "            AmountByCategoryKPI(),\n",
    "            CountByDocTypeKPI(),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02041aec",
   "metadata": {},
   "source": [
    "## Run the Pipeline\n",
    "\n",
    "Load credentials, create a `DatabaseManager`, and run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9019fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load credentials & create a reusable DatabaseManager\n",
    "creds = DatabaseManager.load_credentials(CREDS_PATH)\n",
    "db = DatabaseManager(creds[\"data_warehouse\"])\n",
    "\n",
    "# 2. Create and run the invoice KPI pipeline\n",
    "pipeline = InvoiceKPIPipeline(db, sql_dir=SQL_DIR)\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e239ed3",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5813b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed = time.time() - start_time\n",
    "_, peak_memory = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "print(f\"Pandas (OOP) pipeline executed in {elapsed:.2f} seconds.\")\n",
    "print(f\"Peak RAM usage: {peak_memory / (1024 * 1024):.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
