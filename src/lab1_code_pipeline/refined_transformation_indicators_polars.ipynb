{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae8db668",
   "metadata": {},
   "source": [
    "# Part 1 — Polars Eager Pipeline\n",
    "\n",
    "This notebook is the **Polars (eager mode)** version of the invoice KPI pipeline. It replicates the same logic as the original pandas script (`refined_transformation_indicators.py`) but uses **Polars** instead.\n",
    "\n",
    "**Key concepts demonstrated:**\n",
    "- `pl.read_database_uri()` for reading SQL queries\n",
    "- `pl.when / then / otherwise` for conditional classification\n",
    "- `.join()`, `.group_by()`, `.agg()` for transformations\n",
    "- `pl.concat()` for combining DataFrames\n",
    "- Performance tracking with `time` and `tracemalloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tracemalloc\n",
    "import yaml\n",
    "import polars as pl\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from utils import get_db_engine, load_sql_file\n",
    "\n",
    "# Start performance tracking\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path.cwd()\n",
    "CREDS_PATH = Path(\"C:/Users/roger.lloret/Documents/creds/creds_dmbi.yml\")\n",
    "SQL_DIR = BASE_DIR / \"sql\"\n",
    "TABLE_NAME = \"gen_kpi_ft\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd438e02",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Define Polars-specific helpers for database I/O and invoice classification.\n",
    "\n",
    "| Function | Purpose |\n",
    "|----------|---------|\n",
    "| `read_from_database_pl` | Uses `pl.read_database_uri()` with a full connection URI |\n",
    "| `write_to_database_pl` | Converts to pandas for MySQL writes via `to_sql()` |\n",
    "| `classify_invoices_pl` | Uses `pl.when/then/otherwise` instead of `np.select` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_database_pl(engine, query: str) -> pl.DataFrame:\n",
    "    \"\"\"Reads a SQL query into a Polars DataFrame via the SQLAlchemy engine.\"\"\"\n",
    "    # render_as_string with hide_password=False to include credentials in the URI\n",
    "    uri = engine.url.render_as_string(hide_password=False)\n",
    "    return pl.read_database_uri(query, uri=uri)\n",
    "\n",
    "\n",
    "def write_to_database_pl(engine, df: pl.DataFrame, table_name: str, if_exists: str = \"append\"):\n",
    "    \"\"\"Writes a Polars DataFrame to MySQL by converting to pandas for to_sql.\"\"\"\n",
    "    with engine.begin() as connection:\n",
    "        df.to_pandas().to_sql(table_name, con=connection, if_exists=if_exists, index=False)\n",
    "\n",
    "\n",
    "def classify_invoices_pl(df: pl.DataFrame, column_name: str) -> pl.DataFrame:\n",
    "    \"\"\"Classifies numeric values into categories using Polars when/then/otherwise.\"\"\"\n",
    "    return df.with_columns(\n",
    "        pl.when(pl.col(column_name) < 50)\n",
    "        .then(pl.lit(\"Less than 50\"))\n",
    "        .when((pl.col(column_name) >= 50) & (pl.col(column_name) <= 100))\n",
    "        .then(pl.lit(\"Between 50 and 100\"))\n",
    "        .when(pl.col(column_name) > 100)\n",
    "        .then(pl.lit(\"Greater than 100\"))\n",
    "        .otherwise(pl.lit(\"Invalid Input\"))\n",
    "        .alias(\"category\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58930c55",
   "metadata": {},
   "source": [
    "## 1. Load Credentials & Initialize Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ebc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CREDS_PATH, \"r\") as file:\n",
    "    creds = yaml.safe_load(file)\n",
    "\n",
    "db_engine = get_db_engine(creds[\"data_warehouse\"])\n",
    "print(\"Database engine created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb7e4fa",
   "metadata": {},
   "source": [
    "## 2. Extract Data\n",
    "Load invoices and contracts using SQL files and `pl.read_database_uri()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef98003",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_sql = load_sql_file(SQL_DIR / \"invoices_main.sql\")\n",
    "contracts_sql = load_sql_file(SQL_DIR / \"contracts_main.sql\")\n",
    "\n",
    "invoices_df = read_from_database_pl(db_engine, invoices_sql)\n",
    "contracts_df = read_from_database_pl(db_engine, contracts_sql)\n",
    "\n",
    "print(f\"Invoices: {invoices_df.shape[0]} rows, {invoices_df.shape[1]} columns\")\n",
    "print(f\"Contracts: {contracts_df.shape[0]} rows, {contracts_df.shape[1]} columns\")\n",
    "invoices_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a01393d",
   "metadata": {},
   "source": [
    "## 3. Transform Data\n",
    "- Deduplicate contracts\n",
    "- Classify invoices using `pl.when / then / otherwise`\n",
    "- Cast join keys to `Int64`\n",
    "- Left join invoices with contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9043c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate contracts\n",
    "contracts_df = contracts_df.unique()\n",
    "\n",
    "# Classify invoices\n",
    "invoices_df = classify_invoices_pl(invoices_df, \"total_import_euros\")\n",
    "\n",
    "# Cast join keys to numeric (Int64)\n",
    "invoices_df = invoices_df.with_columns(pl.col(\"contract_id\").cast(pl.Int64, strict=False))\n",
    "contracts_df = contracts_df.with_columns(pl.col(\"contract_id\").cast(pl.Int64, strict=False))\n",
    "\n",
    "# Merge\n",
    "merged_df = invoices_df.join(contracts_df, on=\"contract_id\", how=\"left\")\n",
    "print(f\"Merged: {merged_df.shape[0]} rows, {merged_df.shape[1]} columns\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a0e3b",
   "metadata": {},
   "source": [
    "## 4. Create KPIs\n",
    "- **KPI 1:** Total amount by category and client type\n",
    "- **KPI 2:** Invoice count by document type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddace79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPI 1: Amount by Category & Client Type\n",
    "kpi_category_df = (\n",
    "    merged_df\n",
    "    .group_by([\"category\", \"client_type_description\"])\n",
    "    .agg(pl.col(\"total_import_euros\").sum().alias(\"kpi_value\"))\n",
    "    .with_columns(\n",
    "        (\n",
    "            pl.lit(\"Total amount in euros of the customers with invoices \")\n",
    "            + pl.col(\"category\")\n",
    "            + pl.lit(\" euros and \")\n",
    "            + pl.col(\"client_type_description\")\n",
    "        ).alias(\"kpi_name\")\n",
    "    )\n",
    "    .select([\"kpi_name\", \"kpi_value\"])\n",
    ")\n",
    "\n",
    "# KPI 2: Document Type Count\n",
    "kpi_doctype_df = (\n",
    "    merged_df\n",
    "    .group_by(\"document_type_description\")\n",
    "    .agg(pl.col(\"total_import_euros\").count().cast(pl.Float64).alias(\"kpi_value\"))\n",
    "    .with_columns(\n",
    "        (\n",
    "            pl.lit(\"Number of invoices of invoice type \")\n",
    "            + pl.col(\"document_type_description\")\n",
    "        ).alias(\"kpi_name\")\n",
    "    )\n",
    "    .select([\"kpi_name\", \"kpi_value\"])\n",
    ")\n",
    "\n",
    "print(\"KPI 1 — Amount by Category:\")\n",
    "print(kpi_category_df)\n",
    "print(\"\\nKPI 2 — Document Type Count:\")\n",
    "print(kpi_doctype_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde519a0",
   "metadata": {},
   "source": [
    "## 5. Aggregate and Load to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pl.concat([kpi_category_df, kpi_doctype_df])\n",
    "main_df = main_df.with_columns(pl.lit(date.today()).alias(\"kpi_date\"))\n",
    "output_df = main_df.select([\"kpi_date\", \"kpi_name\", \"kpi_value\"])\n",
    "\n",
    "write_to_database_pl(db_engine, output_df, TABLE_NAME)\n",
    "print(\"ETL Process completed successfully.\")\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c64225",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133df5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed = time.time() - start_time\n",
    "_, peak_memory = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "print(f\"Polars (eager) pipeline executed in {elapsed:.2f} seconds.\")\n",
    "print(f\"Peak RAM usage: {peak_memory / (1024 * 1024):.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
